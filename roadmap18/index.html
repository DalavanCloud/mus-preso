<!DOCTYPE html>
<html>

<head>
	<meta charset="UTF-8" />
	<title>Viz Roadmap</title>
	<script src="slides.js"></script>
	<style>
		.ak h3 {
			font-size: 48px;
		}
		.ak pre {
			margin-top: 10px;
			margin-bottom: 10px;
		}
	</style>
</head>

<body class="ak" style="display: none;">
<section class="slides layout-widescreen template-default">

<article>
	<h1>Viz: Roadmap 2018</h1>
	<p>Wat, 2017/12/07</p>
</article>

<!--

At the previous BlinkOn, I talked about Mus and Compositing. Some things have
changed since then, we've renamed some parts, we've refined our plans. We've
done some work. In this talk, I'm going to give you a progress update and
revised roadmap.

-->

<article>
	<h3>About this talk</h3>

	<ul class="build">
	<li>There was a CPS for Chrome graphics</li>
	<li>We have a goal for 2018</li>
	<li>Chrome Vulkan</li>
	<li>On
		<ul class="build">
			<li>Android</li>
			<li>Windows</li>
		</ul>
	</li>
	<li>How do we get there?</li>
	</ul>
</article>



<!--

Let's start by reviewing where we actually are.

If you went to BlinkOn, this should be familiar to you all.  You've hopefully
seen it before but if you've been too busy coding during past presentations...



-->

<article>
	<h3>You Are Here</h3>

	<ul class="build">
	<li>We have a relocated display compositor (OOP-D)
	<div style="text-align:center" >
		<object data="display-compositor-now.svg" height="260" alt="Servification Context"></object>
	</div>
	</li>
	<li>We have OOP-R
	<div style="text-align:center" >
		<object data="oopr-now.svg	" height="260" alt="Servification Context"></object>
	</div>
	</li>
	</ul>
</article>	


<!--

Cue Queen's "We Want it All". 
We want it all. 

But that means replacing that fuzzy red cloud of new stuff with code. 


-->

<article>
	<h3>We Want This: OOP-D & OOP-R</h3>
	<div style="text-align:center" >
		<object data="tadpole-oopr-combined.svg" height="320" alt="Servification Context"></object>
	</div>
</article>	

<!-- 

I hope that you know this.

-->

<article>
	<h3>Aside: Why Do We Want This</h3>

	<ul class="build">
	<li>Performance!</li>
	<li>~15% reduced command buffer overhead
		<ul class="build">
			<li>paintops vs GL from renderer</li>
			<li>CompositorFrames vs GL from display compositor</li>
		</ul>
	</li>
	<li>~15% from use of Vulkan (maybe more!)</li>
	</ul>
</article>



<!--

First,  I need to talk about Viz interfaces.

I've drawn something like this before. 

This is probably mostly a reminder for you.

But I've added something new: the RasterInterface whose implementation is about
how we connect up OOP-R and OOP-D.

Also: NB red, green and blue boxes 'cause we're in graphics.

And I'm going to label the consumers of these interfaces when I talk about UI

-->

<article>
	<h3>Viz Interfaces</h3>
	<div style="text-align:center" >
		<object data="viz-context-setting.svg" height="480" alt="Servification Context"></object>
	</div>
</article>	


<!--

speak to slide

-->


<article>
	<h3>Aside About UI and Mus</h3>

	<ul class="build">
	<li>We have arranged to run <code>--mus</code> like this:
	<div style="text-align:center" >
		<object data="launchable-mus.svg" height="260" alt="Servification Context"></object>
	</div>
	</li>
	<li>Maybe a lost toy but combining <code>--mus</code> and <code>--enable-viz</code>
	<div style="text-align:center" >
		<object data="launchable-mus-with-viz.svg" height="260" alt="Servification Context"></object>
	</div>
	</li>
	</ul>
</article>	



<!--

In a previous slide I introduced the raster interface...

We need to change the UI to use the raster interface.

speak to the picture...


-->


<article>
	<h3>UI Changes For RasterInterface</h3>

	<ul class="build">
	<li>Change Aura UI like this (Eventually):
	<div style="text-align:center" >
		<object data="launchable-aura-with-viz-rasterinterface.svg" height="260" alt="Servification Context"></object>
	</div>
	</li>
	<li>Change Mus UI like this:
	<div style="text-align:center" >
		<object data="launchable-mus-with-viz-rasterinterface.svg" height="260" alt="Servification Context"></object>
	</div>
	</li>
	</ul>
</article>	



<!--

blther...
-->

<article>
	<h3>Why Change Aura UI to RasterInterface</h3>
	<ul class="build">
	<li>UI raster thread uses GLES2Interface <em>only</em> to upload software-rasterized UI elements</li>
	<li>RasterInterface will eventually do this directly to Vulkan</li>
	<li>Instead of passing through GL to Vulkan texture transport</li>
	<li>In Salamander: switch UI to generating paint item lists</li>
	</ul>
</article>


<!-- 

On to work items.

-->

<article>
	<h3>Work Items</h3>
	<ul class="build">
	<li>I've broken the work items into three groups</li>
	<li>First, Next and Next-Next</li>
	<li>Mea culpa:  I didn't finish setting up the nice webtech Gantt chart thinger...</li>
	</ul>
</article>


<!--

blther...
-->

<article>
	<h3>First: Metrics</h3>
	<ul class="build">
	<li>Tadpole-Vulkan is about performance</li>
	<li>We <em>must</em> have better metrics:
		<ul class="build">
			<li>Existing web platform telemetry <b>m64</b></li>
			<li>Aura UI for Windows: resize and tab dragging <b>m65</b></li>
			<li>Android Chrome UI <b>m65</b></li>
			<li>Aura UI on CrOS <b>m66</b></li>
		</ul>
	</li>
	</ul>
</article>

<!--

blther...
-->

<article>
	<h3>First: Vulkan GPU Bots</h3>
	<ul class="build">
	<li>Android GPU pixel bots with Vulkan drivers <b>m65</b></li>
	<li>Windows GPU pixel bots with Vulkan drivers <b>m65</b></li>
	<li>Linux and CrOS Vulkan bots after.</li>
	</ul>
</article>

<!--

Our work items

-->


<article>
	<h3>First: Sluggish Tadpole: M65</h3>
	<ul>
	<li>The bare minimum to combine OOP-R and OOP-D</li>
	</ul>
	<div style="text-align:center" >
		<object data="viz-inside-sluggish-tadpole.svg" height="480" alt="Servification Context"></object>
	</div>
</article>	


<article>
	<h3>First: Remaining Tasks</h3>
	<ul class="build">
	<li>Surface Sync <b>m65</b></li>
	<li>Skia Bulkupload <b>m66?</b></li>
	</ul>
</article>	



<article>
	<h3>Next: Tasks</h3>
	<ul class="build">
	<li>OOP-R remaining issues <b>m68</b></li>
	<li>Prototype Vulkan rendering pipe on android<b>m66</b> (Front-loaded for Android launch schedule.)</li>
	<li>Android UI
		<ul class="build">
			<li>Existing web platform telemetry <b>m64</b></li>
			<li>Aura UI for Windows: resize and tab dragging <b>m65</b></li>
			<li>Android Chrome UI <b>m65</b></li>
			<li>Aura UI on CrOS <b>m66</b></li>
		</ul>
	
	</ul>
</article>	


<article>
	<h3>Viz Tadpole</h3>
	<div style="text-align:center; padding-top: 20px; overflow: hidden; height:240px;" >
		<object data="tadpole-webplatform-pipeline.svg" width="920" alt="Viz Tadpole pipeline"></object>
	</div>
	<ul class="build">
	<li>Coming to Chrome over the next 2-3 milestones</li>
	<li>A prepatory refactoring for direct compositing: removing the bolded CommandBuffer
	<li>Promises to deliver a 10-15%  performance improvement</li>
	</ul>
</article>

<!--
We have several ways to implement our goal of removing the unnecessary
command buffer.

The current Display Compositor has
a GL backend that  emits serialized GL over a command buffer (in red) to
Chrome's virtualized GPU

To eliminate the use of a command buffer in process...

We could modify (possibly extensively) the GLRenderer backend
to the display compositor to connect to GL directly.

Instead, we plan to switch the compositor to a new Skia/Ganesh backend instead.
-->

<article>
	<h3>Viz Tadpole with Direct Skia Compositing</h3>
	<ul class="build">
	<li>Tadpole DisplayCompositor uses <code><a href="https://cs.chromium.org/chromium/src/cc/output/direct_renderer.h">GLRenderer</a></code>
		<div style="text-align:center; overflow: hidden; height: 200px;" >
			<object data="tadpole-webplatform-gl-directrenderer.svg" height="250" alt="Using GLRenderer"></object>
		</div>
	</li>
	<li>Replace with <code><a href="https://cs.chromium.org/chromium/src/components/viz/service/display/skia_renderer.h">SkiaRenderer</a></code> for direct compositing
		<div style="text-align:center; overflow: hidden; height: 200px;" >
			<object data="tadpole-webplatform-skia-directrenderer.svg" height="250" alt="Skia Renderer instead"></object>
		</div>
	</li>
	<li>Enable the WIP version <code>--use-skia-renderer</code></li>
	</ul>
</article>


<!--

You may have heard me talkign about this before. On several occasions
and might be wondering: why isn't Tadpole and whatnot done yet?

Well, Tadpole is hard. 

Simple for the web platform

As you can see from the picture: 

-->

<article>
	<h3>Aside: Why is Tadpole Hard?</h3>
	<ul class="build">
	<li>Tadpole is conceptually simple for the web platform</li>
	<li>The before and after picture for renderer processes is unchanged:
		<div style="text-align:center; overflow: hidden; height: 240px;" >
			<object data="tadpole-not-hard-webplatform.svg" height="300" alt="Limited Webplatform changes"></object>
		</div>
	</li>
	<li>Only have to alter the setup of CompositorFrame transport</li>
	<li>But Tadpole also requires many browser-side changes</li>
	</ul>
</article>

<!--

I know this is BlinkOn but bear with me while I talk about how the Chrome UI 
does graphics. Unlike the Web platform, the 
Chrome UI graphics pipe has to change a lot.

* Before Viz, the windowing and ui toolkits aura and views have a synchronous functional
call interface to the entire compositor.

* But after relocating the display compositor, we have inserted the new highlighted
asynchronous IPC interface. 


-->

<article>
	<h3>UI Graphics Pipeline Changes</h3>
	<ul class="build">
	<li>Synchronous function call before
		<div style="text-align:center; overflow: hidden; height: 220px;" >
			<object data="current-ui-pipeline.svg" height="260" alt="Limited Webplatform changes"></object>
		</div>
	</li>
	<li>Asynchronous IPC after:
		<div style="text-align:center; overflow: hidden; height: 220px;" >
			<object data="tadpole-ui-pipeline.svg" height="260" alt="Limited Webplatform changes"></object>
		</div>
	</li>
	</ul>
</article>


<!--
Handling the consequences of Introducing this asynchrony is why Tadpole
is a large project.

You can see the bug for all the details. Or even better, find some some bugs
that you might like to help with.

A quick status update on where we are:

-->
<article>
	<h3>Tadpole Status (<a href="http://crbug/601863">crbug/601863</a>)</h3>
	<ul class="build">
	<li>Surface References to improve tracking of objects <em>on in 63</em> </li>
	<li>Improved CompositorFrame eviction <em>on in 64</em> </li>
	<li>Surface Synchronization so UI can atomically update sizes of web platform children <em>on in 64</em></li>
	<li>Cross-process Tab readback <em>on in 64</em></li>
	<li>Revised event targeting <em>on in 64</em></li>
	<li>Improved occlusion culling <em>on in 64</em></li>
	<li>SkiaRenderer <em>performant in 67</em></li>
	</ul>
</article>

<!--

OOP Rasterization

Another parallel effort for Viz leading towards Salamander Viz is OOP
Rasterization.

Centralizing the display compositor promises to reduce command buffer overhead. But
so does delegating all rasterization to the Viz process.

This is the point of OOP rasterization: delegating raster to Viz via out of process
serialized paint operations.

-->
<article>
	<h3>Parallel Effort: OOP Rasterization</h3>
	<ul class="build">
	<li>Centralizing the display compositor permits reducing command buffer overhead</li>
	<li>So does delegating serialized paint ops to Viz for <strong>O</strong>ut <strong>O</strong>f <strong>P</strong>rocess rasterization</li>
	<li>Partial implementation behind flag: <code>--enable-gpu-rasterization <br>--enable-oop-rasterization</code></li>
	</ul>
</article>


<!-- 

* Currently, each web platform client generates paint ops and then
uses Skia/Ganesh to convert these into a serialized GL stream that it
sends these to the GPU process via a command buffer.

* With OOP rasterization, we instead serialize the paint ops in the
renderer and ship them (re-using the underlying CommandBuffer) to Viz
for rasterization.

This substitution will improve performance because this lower
highlighted bar of serialized paint ops is smaller and cheaper to
serialize / deserialize than this upper highlighted bar of serialized
GL commands.

-->
<article>
	<h3>OOP  Rasterization</h3>
	<ul class="build">
	<li>Now: each web platform client generates GL
		<div style="text-align:center; overflow: hidden; height: 240px;" >
			<object data="current-webplatform-pipeline-highlighted.svg" height="300" alt="Limited Webplatform changes"></object>
		</div>
	</li>
	<li>Next: OOP rasterization serializes paint ops and rasterizes in Viz
		<div style="text-align:center; overflow: hidden; height: 240px;" >
			<object data="current-webplatform-oops.svg" height="300" alt="Limited Webplatform changes"></object>
		</div>
	</li>
	</ul>
</article>


<!--


We can combine Tadpole, OOP raster and the SkiaRenderer
compositor.

This is a significant milestone because it is the prerequisite for the
use of Vulcan. 

Going left to right...

* here we have the same CC paint / commit appratus as before
* paint ops are handled as I already discussed for OOP raster: serialized
in the renderer and shipped to Viz for rasterization
* the CC impl thread prepares CompositorFrame instances and sends them to Viz
* As with Tadpole, the display compositor is in Viz and handles the provided CompositorFrame
* The display compositor uses the direct compositing SkiaRenderer backend that I talked
about previously
* The Skia rasterizer handling the paintops has been modified. Here, Skia creates Chrome closures wrapping GL draw calls corresponding to the paint ops.
* These are PostTask-ed to the SkiaRenderer so that can choose how rasterization and compositing drawops are scheduled to the GPU

Note in particular: we have no GL CommandBuffer use.
-->
<article>
	<h3>Combined Tadpole and OOP Rasterization</h3>
	<div style="text-align:center; padding-top: 50px; overflow: hidden; height: 300px;" >
		<object data="tadpole-oops-combined.svg" height="370" alt="Tadpole and OOPS Combined"></object>
	</div>
	<ul>
	<li>Note absence of GL command buffers</li>
	<li>Improves both raster and compositing performance</li>
	</ul>
</article>


<!--


As has perhaps become obvious now, eliminating the GL command buffer from both webpage rasterization
and compositing has an ulterior motive beyond eliminating its serialization
overhead.

It is not possible to implement a command buffer for the Vulkan API without
losing many of the benefits of the Vulkan API.

There is however (conveniently) a Skia Ganesh Vulkan backend that 
we could use for both rasterization and the SkiaRenderer. I added it to the
diagram here. It should be obvious why I talked earlier about the 
SkiaRenderer.

And: why do we care to use Vulkan? 

We expect an additional 10-15% performance improvement from the combination
of command buffer removal and the use of Vulkan.

-->

<article>
	<h3>Enabling Vulkan</h3>
	<ul class="build">
	<li>Vulkan API is not ammenable to implementing a command buffer</li>
	<li>Skia has a Vulkan backend
		<div style="text-align:center; overflow: hidden; height: 280px;" >
			<object data="tadpole-oops-combined-vulkan.svg" height="320" alt="First class OOPIFs"></object>
		</div>
	</li>
	<li>Vulkan promises 10-15% better performance beyond the GL implementation for both SkiaRenderer and paint op rasterization</li>
	</ul>
</article>


<!-- 

If you care about WebGL, you're probably wonder what would happen
to it without a command buffer. Have no fear, it's still here because
WebGL requires it.

We have two ways to connect the GPU service 

-->
<article>
	<h3>Aside: WebGL Requires CommandBuffer</h3>
	<ul class="build">
	<li>A platform-specific API could permit texture sharing with Native GL
		<div style="text-align:center; overflow: hidden; height: 240px;" >
			<object data="tadpole-oops-combined-vulkan-webgl-texturesharing.svg" height="280" alt="First class OOPIFs"></object>
		</div>
	</li>
	<li>Angle for Vulkan (aka Vangle) would permit direct interop
		<div style="text-align:center; overflow: hidden; height: 240px;" >
			<object data="tadpole-oops-combined-vulkan-webgl-vangle.svg" height="280" alt="First class OOPIFs"></object>
		</div>
	</li>
	</ul>
</article>


<!--

At the beginning of the talk, I said that Viz is also intended
to remove the  rasterization and compositing overhead 
needed to support for site-isolation.

Site isolation is desirable because it improves 
security by placing each origin domain in a different
renderer process.

But currently, general use of site isolation imposes a graphics
performance toll.

A single top-level page using site isolation might look like the
schematic. ...explain picture...

The embedded iframe in light red allocates GPU memory and rasterizes
the entire red region. (Though afaik, there is wip to clip it to the
bounds of the embedding page.)

But the dark red region is unecessarily allocated and rasterized.

-->
<article>
	<h3>Explaining the Site Isolation Graphics Toll</h3>
	<ul class="build">
	<li>Site isolation improves security</li>
	<li>With site-isolation,  a single top-level page like this:
		<div style="text-align:center; overflow: hidden; height: 200px;" >
			<object 
				data="oopif-tool-page.svg" height="280" alt="OOPIF containing page"></object>
		</div>
	</li>
	<li>Unnecessarily allocates GPU memory and rasterizes the red region:
		<div style="text-align:center; padding-top: -80px;" >
			<object data="oopif-toll-double-raster.svg" height="280" alt="OOPIF containing page"></object>
		</div>

	</li>
	</ul>
</article>	


<!-- 

This problem exists because aggregation is misplaced. Currently, we
aggregate after we layerize.

...speak to the picture...

Because we layerize in the renderers and then aggregate in the Display
Compositor in Viz

With the result that we send paint ops (and hence rasterize)
everything that might be needed to composite.

And only then do we aggregate the contributions from the all of the
different renderers contributing to the page.

But by then, it's too late: we've already over-allocated GPU memory
and done unnecessary raster work.

-->
<article>
	<h3>Now: Aggregation <em>After</em> Rasterization </h3>
	<div style="text-align:center; padding-top: 20px; overflow: hidden; height: 320px;" >
		<object data="tadpole-oops-combined-two-renderers.svg" height="380" alt="Tadpole and OOPS Combined"></object>
	</div>
	<ul class="build">
	<li>Makes rasterization decisions locally in the renderers</li>
	<li>So rasterize everything that <em>might</em> be needed</li>
	<li>Display Compositor aggregates the contributed layers</li>
	<li>Result: redundant rasterization</li>
	</ul>

</article>	


<!--

That brings us to Salamander. The cute amphibian name for what comes
after Tadpole and the last step of Viz development that has seen

 Salamander is about re-ordering aggregation with
rasterization.

Expand explanation.

-->
<article>
	<h3>Salamander: Aggregation Before Raster</h3>
	<div style="text-align:center; padding-top: 20px; overflow: hidden; height: 340px;" >
		<object data="salamander.svg" height="400" alt="Salamander: aggregation preceeds raster"></object>
	</div>
	<ul class="build">
	<li>Start with same paint ops</li>
	<li>Add layerization data from property trees</li>
	<li>Aggregate centrally</li>
	<li>Rasterize and composite the smallest necessary set of paint ops</li>
	</ul>

</article>	


<!--
Salmander development is probably still quite a ways out. Let me wrap
up by summarizing where we are now.

* The first part of Viz project is Tadpole were we relocate the DisplayCompositor
to Viz. On by 66 we hope.

* OOP rasterization is happening in parallel but still requires a great deal of effort. Ideally not long after Tadpole. Say Q2 of 2018.

* The SkiaRenderer compositor backend 

With these three items complete, then we can start the next  additional in-parallel 
efforts. Ideally in Q3 of 2018:

* Use of Vulkan graphics
* Salamander's re-ordering of layerization and paint item selection
-->
<article>
	<h3>Summary: Viz Status</h3>
	<ul class="build">
	<li>Underway now
		<ul class="build">
		<li>Tadpole: relocate the DisplayCompositor to Viz <em>in 66</em></li>
		<li>OOP Rasterization in Viz <em>Q2 2018</em></li>
		<li>SkiaRenderer <em>in 67</em></li>
		</ul>
	</li>
	<li>After the above <em>starting Q3 2018</em>
		<ul class="build">
		<li>Vulkan graphics</li>
		<li>Salamander: central layerization</li> 
		</ul>
	</li>
</article>

<article>
	<h3> Viz Take-aways</h3>
	<ul class="build">
	<li>Two ways to think about Viz:
		<ul class="build">
		<li>Servicification of graphics in Chrome</li>
		<li>A better GPU process</li>
		</ul>
	</li>
	<li>Viz improves webplatform graphics three ways:
		<ul class="build">
		<li>10-15% performance benefit from removing command buffers</li>
		<li>Vulkan support for another 10-15% performance benefit</li>
		<li>Central aggregation for toll-free site-isolation support</li>
		</ul>
	</li>
	</ul>
</article>	

</section>
</body>
</html>
